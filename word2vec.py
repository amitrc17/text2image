# -*- coding: utf-8 -*-
"""
Created on Sat Nov 18 08:41:35 2017

@author: amitrc
"""
import collections
import os
from tempfile import gettempdir
import zipfile

import numpy as np

import tensorflow as tf
from skip_thoughts import configuration
from skip_thoughts import encoder_manager
import scipy.spatial.distance as sd
from pycocotools.coco import COCO
from sklearn.decomposition import PCA

skipthought_vocab_path = 'checkpoints/skipthought/vocab.txt'
skipthought_embedding_matrix_path = 'checkpoints/skipthought/embeddings.npy'
skipthought_checkpoint_path = 'checkpoints/skipthought/model.ckpt-501424'


# Loading Captions for COCO
#cap_path = 'coco/annotations/captions_train2014.json'
#cat_path = 'coco/annotations/instances_train2014.json'
#print('Loading Captions')
#coco_cap = COCO(cap_path)
#captions = coco_cap.loadAnns(coco_cap.getAnnIds())
#words = [caption['caption'] for caption in captions]

# CUB-2011 Captions generated by the model - Show & Tell [Vinyals et. al 2016]
cap_path = 'bird_caps_big.npy'

encoder = encoder_manager.EncoderManager()
encoder.load_model(configuration.model_config(), vocabulary_file=skipthought_vocab_path,
                   embedding_matrix_file=skipthought_embedding_matrix_path,
                   checkpoint_path=skipthought_checkpoint_path)

compressor = PCA(n_components=128)
print('Loading Captions')
bird_caps = np.load(cap_path)
print('loaded captions -', len(bird_caps))
words = [bird_cap[0] for bird_cap in bird_caps]
##words = [key for key in dictionary.keys()]
encodings = encoder.encode(words, verbose=True)
print('Performing PCA...')
compressor.fit(np.array(encodings))
encodings = compressor.transform(encodings)
mapping = []

for idx, encoding in enumerate(encodings):
    mapping.append((encoding, bird_caps[idx][1]))
mapping = np.array(mapping)
np.save('bird_mappings_big.npy', mapping)
#np.save('wordencodings.npy', mapping)
#mapping = np.load('new_mapping.npy')
#np.save('new_mapping.npy', new_mapping)
    
for i in range(5):
    idx = np.random.randint(0,len(words))
    encoding = encodings[idx]
    scores = sd.cdist([encoding],encodings, 'cosine')[0]
    sorted_ids = np.argsort(scores)
    print('SENTENCE = ', words[idx])
    print('Closest sentences - ')
    for j in range(10):
        print(words[sorted_ids[j]])

